import streamlit as st
import pandas as pd
import re
import io
from datetime import datetime

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏≠‡∏õ
st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏á‡∏≤‡∏ô‡∏ä‡∏µ‡∏ß‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤ ‡∏°.3", layout="wide")

# ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß (Session State)
if 'processed_data' not in st.session_state:
    st.session_state['processed_data'] = None  # ‡πÄ‡∏Å‡πá‡∏ö DataFrame ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
if 'history' not in st.session_state:
    st.session_state['history'] = []           # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå

st.title("üìã ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏ß‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤ ‡∏°.3")
st.write("‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏à‡∏î‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏π‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå")

# --- Sidebar: ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ---
with st.sidebar:
    st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà"):
        st.session_state['processed_data'] = None
        st.session_state['history'] = []
        st.rerun()
    
    st.markdown("---")
    st.subheader("üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
    if st.session_state['history']:
        for item in reversed(st.session_state['history']):
            st.info(f"üìÑ {item['file']}\n\nüïí {item['time']}")
    else:
        st.write("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏° (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
def clean_name_parts(raw_name):
    prefixes = [r'^‡∏ô‡∏≤‡∏¢', r'^‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß', r'^‡∏î\.‡∏ä\.', r'^‡∏î\.‡∏ç\.', r'^‡πÄ‡∏î‡πá‡∏Å‡∏ä‡∏≤‡∏¢', r'^‡πÄ‡∏î‡πá‡∏Å‡∏´‡∏ç‡∏¥‡∏á', r'^‡∏î‡∏ä\.', r'^‡∏î‡∏ç\.']
    s = str(raw_name).strip()
    is_valid_thai = bool(re.search(r'[\u0e00-\u0e7f]', s))
    for p in prefixes: s = re.sub(p, '', s).strip()
    parts = s.split(maxsplit=1)
    fname = parts[0] if len(parts) > 0 else "-"
    lname = parts[1] if len(parts) > 1 else "-"
    return fname, lname, (not is_valid_thai or lname == "-")

def get_group_info(section_text):
    text = str(section_text)
    g_num = re.search(r'(‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà\s*\d+)', text)
    g_name = re.search(r'\)\s*(.*)', text)
    res_num = g_num.group(1) if g_num else ""
    res_name = g_name.group(1).strip() if g_name else ""
    return f"{res_num} {res_name}".strip() if res_num and res_name else (res_num or res_name or text)

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå ---
# ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡πà‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
if st.session_state['processed_data'] is None:
    uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Padlet (CSV ‡∏´‡∏£‡∏∑‡∏≠ Excel)", type=["csv", "xlsx", "xls"])
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            else:
                df = pd.read_excel(uploaded_file)
            
            df.columns = [str(c).strip() for c in df.columns]
            if '‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô' in df.columns:
                df = df[~df['‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô'].str.contains("‡∏ï‡∏£‡∏∞‡∏Å‡∏π‡∏•", na=False)]

            temp_results = []
            for _, row in df.iterrows():
                full_text = f"{row.get('‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', '')} {row.get('‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤', '')}"
                st_no = re.search(r'‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà\s*(\d+)', full_text)
                no = st_no.group(1) if st_no else "-"
                
                nm_match = re.search(r'(‡∏ô‡∏≤‡∏¢|‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß|‡∏î\.‡∏ä\.|‡∏î\.‡∏ç\.|‡πÄ‡∏î‡πá‡∏Å‡∏ä‡∏≤‡∏¢|‡πÄ‡∏î‡πá‡∏Å‡∏´‡∏ç‡∏¥‡∏á)\s*([^\s\d]+)\s+([^\s\d]+)', full_text)
                raw_name = nm_match.group(0) if nm_match else str(row.get('‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')).split('(')[0].strip()
                
                fname, lname, is_unk = clean_name_parts(raw_name)
                all_act = re.search(r'‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà\s*(\d+\.?\d*)', full_text)
                
                temp_results.append({
                    '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà': no, '‡∏ä‡∏∑‡πà‡∏≠': fname, '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•': lname,
                    '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°': get_group_info(row.get('‡∏™‡πà‡∏ß‡∏ô', '')),
                    '‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°': all_act.group(1) if all_act else None,
                    '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': '‚úì', 'is_unknown': is_unk
                })
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á Session
            st.session_state['processed_data'] = pd.DataFrame(temp_results)
            st.session_state['history'].append({
                "file": uploaded_file.name, 
                "time": datetime.now().strftime("%d/%m/%Y %H:%M")
            })
            st.rerun() # ‡∏£‡∏µ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏à‡∏≤‡∏Å Session
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
else:
    # --- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ ---
    res_df = st.session_state['processed_data']
    st.success(f"‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {st.session_state['history'][-1]['file']}")

    # 1. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°
    st.subheader("‚úÖ 1. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô ‡∏°.3")
    df_act = res_df[res_df['‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°'].notna()].copy()
    if not df_act.empty:
        df_act = df_act.drop_duplicates(subset=['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°'])
        pivot = df_act.pivot(index=['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°', 'is_unknown'], 
                            columns='‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°', values='‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞').fillna('-').reset_index()
        
        pivot['sort_key'] = pivot.apply(lambda r: (r['is_unknown'], int(r['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']) if str(r['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']).isdigit() else 999, r['‡∏ä‡∏∑‡πà‡∏≠']), axis=1)
        pivot = pivot.sort_values('sort_key').drop(columns=['is_unknown', 'sort_key'])
        st.dataframe(pivot, use_container_width=True)

        # ‡∏õ‡∏∏‡πà‡∏° Excel
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            pivot.to_excel(writer, index=False, sheet_name='Summary_M3')
        st.download_button(label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ (Excel)", data=output.getvalue(), file_name="‡∏™‡∏£‡∏∏‡∏õ‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô_‡∏°3.xlsx")

    # 2. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ô‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°
    st.markdown("---")
    st.subheader("‚ö†Ô∏è 2. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏•‡∏Ç‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°)")
    df_no_act = res_df[res_df['‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°'].isna()].copy()
    if not df_no_act.empty:
        summ_no = df_no_act.groupby(['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°', 'is_unknown']).size().reset_index(name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô')
        summ_no['sort_key'] = summ_no.apply(lambda r: (r['is_unknown'], int(r['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']) if str(r['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']).isdigit() else 999, r['‡∏ä‡∏∑‡πà‡∏≠']), axis=1)
        st.table(summ_no.sort_values('sort_key').drop(columns=['is_unknown', 'sort_key']))
