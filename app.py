import streamlit as st
import pandas as pd
import re
import io
from datetime import datetime

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏≠‡∏õ‡πÉ‡∏´‡πâ‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î Sidebar
st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏á‡∏≤‡∏ô‡∏ä‡∏µ‡∏ß‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤ ‡∏°.3", layout="wide", initial_sidebar_state="collapsed")

# ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ (Session State)
if 'processed_data' not in st.session_state:
    st.session_state['processed_data'] = None
if 'history' not in st.session_state:
    st.session_state['history'] = []

st.title("üìã ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏ß‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤ ‡∏°.3")
st.write("‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏á‡∏≤‡∏ô Padlet: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 10 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)")
st.markdown("---")

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
def clean_name_parts(raw_name):
    prefixes = [r'^‡∏ô‡∏≤‡∏¢', r'^‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß', r'^‡∏î\.‡∏ä\.', r'^‡∏î\.‡∏ç\.', r'^‡πÄ‡∏î‡πá‡∏Å‡∏ä‡∏≤‡∏¢', r'^‡πÄ‡∏î‡πá‡∏Å‡∏´‡∏ç‡∏¥‡∏á', r'^‡∏î‡∏ä\.', r'^‡∏î‡∏ç\.']
    s = str(raw_name).strip()
    is_valid_thai = bool(re.search(r'[\u0e00-\u0e7f]', s))
    for p in prefixes: s = re.sub(p, '', s).strip()
    parts = s.split(maxsplit=1)
    fname = parts[0] if len(parts) > 0 else "-"
    lname = parts[1] if len(parts) > 1 else "-"
    return fname, lname, (not is_valid_thai or lname == "-")

def get_group_info(section_text):
    text = str(section_text)
    g_num = re.search(r'(‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà\s*\d+)', text)
    g_name = re.search(r'\)\s*(.*)', text)
    res_num = g_num.group(1) if g_num else ""
    res_name = g_name.group(1).strip() if g_name else ""
    return f"{res_num} {res_name}".strip() if res_num and res_name else (res_num or res_name or text)

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏µ‡∏ô) ---
uploaded_file = st.file_uploader("üì• ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠ Update ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (CSV ‡∏´‡∏£‡∏∑‡∏≠ Excel)", type=["csv", "xlsx", "xls"])

# ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
if uploaded_file:
    try:
        raw_bytes = uploaded_file.getvalue()
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(io.BytesIO(raw_bytes), encoding='utf-8-sig')
        else:
            df = pd.read_excel(io.BytesIO(raw_bytes))
            
        df.columns = [str(c).strip() for c in df.columns]
        if '‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô' in df.columns:
            df = df[~df['‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô'].str.contains("‡∏ï‡∏£‡∏∞‡∏Å‡∏π‡∏•", na=False)]

        temp_results = []
        for _, row in df.iterrows():
            txt = f"{row.get('‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', '')} {row.get('‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤', '')}"
            st_no = re.search(r'‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà\s*(\d+)', txt)
            nm_match = re.search(r'(‡∏ô‡∏≤‡∏¢|‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß|‡∏î\.‡∏ä\.|‡∏î\.‡∏ç\.|‡πÄ‡∏î‡πá‡∏Å‡∏ä‡∏≤‡∏¢|‡πÄ‡∏î‡πá‡∏Å‡∏´‡∏ç‡∏¥‡∏á)\s*([^\s\d]+)\s+([^\s\d]+)', txt)
            raw_name = nm_match.group(0) if nm_match else str(row.get('‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')).split('(')[0].strip()
            fname, lname, is_unk = clean_name_parts(raw_name)
            act = re.search(r'‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà\s*(\d+\.?\d*)', txt)
            
            temp_results.append({
                '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà': st_no.group(1) if st_no else "-",
                '‡∏ä‡∏∑‡πà‡∏≠': fname, '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•': lname,
                '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°': get_group_info(row.get('‡∏™‡πà‡∏ß‡∏ô', '')),
                '‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°': act.group(1) if act else None,
                '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': '‚úì', 'is_unknown': is_unk
            })
        
        new_df = pd.DataFrame(temp_results)
        st.session_state['processed_data'] = new_df
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ (10 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
        current_time = datetime.now().strftime("%H:%M:%S (%d/%m)")
        st.session_state['history'].append({
            "file": uploaded_file.name,
            "time": current_time,
            "raw_file": raw_bytes
        })
        
        if len(st.session_state['history']) > 10:
            st.session_state['history'] = st.session_state['history'][-10:]
            
        st.success(f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name}")
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ï‡πâ‡∏ä‡πà‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ) ---
if st.session_state['history']:
    with st.expander(f"üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ({len(st.session_state['history'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)", expanded=True):
        for idx, item in enumerate(reversed(st.session_state['history'])):
            h_col1, h_col2, h_col3 = st.columns([3, 2, 1])
            with h_col1:
                st.write(f"üìÑ {item['file']}")
            with h_col2:
                st.caption(f"üïí {item['time']}")
            with h_col3:
                st.download_button(
                    label="üì• ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö",
                    data=item['raw_file'],
                    file_name=item['file'],
                    key=f"hist_{idx}"
                )

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏• ---
if st.session_state['processed_data'] is not None:
    res_df = st.session_state['processed_data']
    st.markdown("---")
    
    st.subheader("‚úÖ 1. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô ‡∏°.3 (‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)")
    df_act = res_df[res_df['‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°'].notna()].copy()
    if not df_act.empty:
        pivot = df_act.drop_duplicates(subset=['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°']).pivot(
            index=['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°', 'is_unknown'], 
            columns='‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°', values='‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞').fillna('-').reset_index()
        
        def sort_logic(row):
            no = int(row['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']) if str(row['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']).isdigit() else 999
            return (row['is_unknown'], no, row['‡∏ä‡∏∑‡πà‡∏≠'])

        pivot['sort_key'] = pivot.apply(sort_logic, axis=1)
        pivot = pivot.sort_values('sort_key').drop(columns=['is_unknown', 'sort_key'])
        st.dataframe(pivot, use_container_width=True)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            pivot.to_excel(writer, index=False)
        st.download_button(label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô Excel", data=output.getvalue(), file_name="‡∏™‡∏£‡∏∏‡∏õ‡∏á‡∏≤‡∏ô_‡∏°3.xlsx")

    # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°
    st.markdown("---")
    st.subheader("‚ö†Ô∏è 2. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (‡∏•‡∏∑‡∏°‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏•‡∏Ç‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°)")
    df_no_act = res_df[res_df['‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°'].isna()].copy()
    if not df_no_act.empty:
        summ_no = df_no_act.groupby(['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', '‡∏ä‡∏∑‡πà‡∏≠', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°', 'is_unknown']).size().reset_index(name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô')
        summ_no['sort_key'] = summ_no.apply(lambda r: (r['is_unknown'], int(r['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']) if str(r['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']).isdigit() else 999, r['‡∏ä‡∏∑‡πà‡∏≠']), axis=1)
        st.table(summ_no.sort_values('sort_key').drop(columns=['is_unknown', 'sort_key']))
